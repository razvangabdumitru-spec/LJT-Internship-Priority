LJT-Internship-Priority

Ranked priority (exactly 5 candidate themes, with facts cited from memory)

1) LLM reasoning & verifiable logical reasoning — Top priority
- Why (uses criteria: recency, specificity, demonstrable experience):
  - Recency: First-author paper "SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond" (2025).
  - Specificity: Paper title focuses on synthesizing verifiable reasoning data and learning logical reasoning (direct match to "LLM Reasoning").
  - Demonstrable experience: Memory records Junteng Liu as first author and notes the paper "Has GitHub code repository".
- Memory facts cited: "SynLogic... (2025) - First author"; "Has GitHub code repository".

2) Hallucination and chart understanding in Vision–Language Models (VLMs)
- Why (uses criteria: recency, specificity, demonstrable experience):
  - Recency: First-author paper "On the Perception Bottleneck of VLMs for Chart Understanding" (2025).
  - Specificity: Explicit focus on perception bottleneck and chart understanding — a concrete VLM task related to hallucination.
  - Demonstrable experience: First author and memory indicates a GitHub repo (Vision4Chart).
- Memory facts cited: "On the Perception Bottleneck of VLMs for Chart Understanding (2025) - First author"; "Has GitHub code repository: Vision4Chart"; interest: "Hallucination in Vision-Language Models".

3) LLM truthfulness and interpretability
- Why (uses criteria: demonstrable experience, specificity, recency):
  - Demonstrable experience: First-author paper "On the Universal Truthfulness Hyperplane Inside LLMs" published at EMNLP 2024 and associated GitHub repo (Universal_Truthfulness_Hyperplane).
  - Specificity: Matches stated research interest "LLM truthfulness and Interpretability" in memory.
  - Recency/community validation: EMNLP 2024 is a recent peer-reviewed venue.
- Memory facts cited: "On the Universal Truthfulness Hyperplane Inside LLMs" (2024) - First author; "Published at EMNLP 2024"; "Has GitHub code repository: Universal_Truthfulness_Hyperplane"; research interest: "LLM truthfulness and Interpretability".

4) Inner-representation approaches to hallucination mitigation (in-context sharpness)
- Why (uses criteria: demonstrable experience, specificity, collaborative strength):
  - Demonstrable experience: Co-author on ICML 2024 paper "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation".
  - Specificity: Targets inner representations and hallucination mitigation — connects to both truthfulness and VLM hallucination themes.
  - Collaborative strength: Publication at ICML 2024 as co-author indicates contribution in a top venue.
- Memory facts cited: "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation" (2024) - Published at ICML 2024; co-author includes Junteng Liu.

5) Evaluation & model adaptation (benchmarks and parameter-efficient modules)
- Why (uses criteria: demonstrable experience, breadth, supporting value):
  - Demonstrable experience: Co-author on NeurIPS 2023 papers "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models" and "Composing Parameter-Efficient Modules with Arithmetic Operations".
  - Breadth/supporting value: Benchmarking and parameter-efficient modules support empirical validation across the higher-priority themes, but are less central to the stated core interests.
- Memory facts cited: "C-Eval... (2023) - Published at NeurIPS 2023"; "Composing Parameter-Efficient Modules with Arithmetic Operations (2023) - NeurIPS 2023"; co-author listings include Junteng Liu.

If time allows next week (two recommended improvements, no new achievements invented)
1) Highlight SynLogic on the GitHub landing/profile
- Action: Feature SynLogic (2025) as the primary project in the profile README: brief blurb linking to the paper and the SynLogic code repository and a 1–2 sentence description of what the code reproduces.
- Memory basis: SynLogic is first-author (2025) and memory notes a GitHub code repository exists.
- Explicit uncertainty: Memory states the SynLogic repo exists but does not include the exact repository URL or confirm public visibility or presence of demo notebooks; verify repo URL and visibility before adding direct links.

2) Pin and surface the three most relevant repos + Google Scholar
- Action: Pin Vision4Chart, SynLogic, and Universal_Truthfulness_Hyperplane on the GitHub profile and add a "Selected Publications" section linking to the Google Scholar profile and the code repositories.
- Memory basis: The three papers and associated code repositories and the Google Scholar profile URL are present in memory.
- Explicit uncertainty: Memory indicates code repos exist but does not provide exact GitHub URLs or confirm whether they are already pinned; confirm repo names/URLs and public visibility prior to pinning/linking.

Notes and constraints
- All claims above are drawn solely from the memory graph: publications (titles, years, authorship roles), stated research interests, and indications of associated GitHub code repositories.
- I have not added any personal details beyond what memory contains.
- Uncertainties were explicitly noted where memory records the existence of code repositories but does not provide exact URLs or visibility status.

Top-priority pick (single theme to emphasize this week)
- Emphasize "LLM reasoning & verifiable logical reasoning (SynLogic, 2025)" on the GitHub landing page this week because it maximizes the three criteria required (recency: 2025; specificity: logical reasoning / verifiable data synthesis; demonstrable experience: first-author + code repo noted in memory).