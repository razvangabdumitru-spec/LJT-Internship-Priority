Priority ranking of 5 candidate PhD internship research themes for Junteng Liu

Ranking criteria (applied simultaneously):
1. Recency of publications and internships (more recent = higher priority)
2. Specificity: presence of first-author publications or code repos tied to the theme
3. Demonstrable experience vs. aspirational interest: internships and co-authorships weigh more than stated interests alone

1) LLM truthfulness and interpretability — Rank #1
- Justification (memory facts cited):
  - "Research interests include LLM truthfulness and Interpretability" (memory)
  - First-author publication: "On the Universal Truthfulness Hyperplane Inside LLMs" (2024) at EMNLP 2024 (memory)
  - Has GitHub code repository: "Universal_Truthfulness_Hyperplane" (memory)
  - Internship and advisor relations supporting LLM work: co-author Prof. Yu Cheng (memory)
  - Criteria used: recency (2024 EMNLP), specificity (first-author + code repo), demonstrable experience (publication)

2) LLM reasoning & reinforcement learning — Rank #2
- Justification (memory facts cited):
  - "Research interests include LLM Reasoning and Reinforcement Learning" (memory)
  - First-author publication relevant to reasoning: "SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond" (2025) — First author and has GitHub code repo (memory)
  - Criteria used: recency (2025 publication), specificity (first-author + code repo), demonstrable experience (publication)

3) Hallucination in vision-language models (VLMs) / hallucination mitigation — Rank #3
- Justification (memory facts cited):
  - "Research interests include Hallucination in Vision-Language Models (VLM)" (memory)
  - First-author publication: "On the Perception Bottleneck of VLMs for Chart Understanding" (2025) — First author; GitHub code repo: Vision4Chart (memory)
  - Co-authored ICML 2024 paper on hallucination mitigation: "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation" (ICML 2024) (memory)
  - Criteria used: recency (2025 & 2024), specificity (first-author + code repo), demonstrable experience (ICML paper co-authorship)

4) Evaluation & benchmarks for foundation models (e.g., C-Eval) — Rank #4
- Justification (memory facts cited):
  - Co-author on "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models" (NeurIPS 2023) (memory)
  - This demonstrates experience building evaluation suites and benchmarks relevant to foundation models
  - Criteria used: specificity (NeurIPS publication), demonstrable experience (co-authorship), but lower recency (2023)

5) Parameter-efficient model composition / model modularity — Rank #5
- Justification (memory facts cited):
  - Co-author on "Composing Parameter-Efficient Modules with Arithmetic Operations" (NeurIPS 2023) (memory)
  - Demonstrates experience with parameter-efficient methods and modular composition
  - Criteria used: specificity (NeurIPS publication), demonstrable experience (co-authorship), but lower recency and fewer first-author signals compared to higher-ranked themes

If time allows next week (two prioritized changes):
1. Add a focused README + example notebook for the top-ranked theme (LLM truthfulness and interpretability) that highlights experiments/code from the "Universal_Truthfulness_Hyperplane" repository and links to the EMNLP 2024 paper (memory) — this leverages existing first-author work and code.
2. Create a short walkthrough demo or README excerpt from the 2025 "SynLogic" project showing dataset synthesis and example results to support LLM reasoning & RL interest (memory). 

Notes on uncertainties from memory: 
- Memory lists GitHub code repository names ("Universal_Truthfulness_Hyperplane", "Vision4Chart", "SynLogic"), but does not provide exact URLs; I did not invent URLs.
- Memory indicates internships and advisors but does not specify exact roles/tasks performed during each internship; prioritization uses publications and co-authorships when available rather than assumed internship task details.
- If you want direct links or want the PRIORITY.md committed to a different repository owner, that information is missing from memory; I created the public repo under GitHub account 'razvangabdumitru-spec' because repository creation used the authenticated account present in the environment, not the memory profile of 'Vicent0205'.
